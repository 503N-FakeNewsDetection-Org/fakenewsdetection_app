name: Retrain‑Text‑Model

on:
  schedule:
    - cron: "0 0 * * 0"   # weekly Sunday midnight
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  train-deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install torch==2.6.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu \
            transformers pandas scikit-learn numpy fastapi uvicorn pydantic \
            azure-storage-blob python-dotenv mlflow tqdm unittest

    - name: Download production weights & user CSV
      env:
        AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      run: |
        python - <<'PY'
        import os, pathlib
        from azure.storage.blob import BlobServiceClient
        conn = os.environ['AZURE_STORAGE_CONNECTION_STRING']
        svc  = BlobServiceClient.from_connection_string(conn)
        containers = {
            'model': (os.getenv('MODELS_CONTAINER', 'fakenewsdetection-models'), os.getenv('MODEL_BLOB', 'model.pt'), 'text_model/model.pt'),
            'csv':   (os.getenv('CSV_CONTAINER', 'fakenewsdetection-csv'),      os.getenv('CSV_BLOB',  'user_data.csv'),      'datasets/text_data/user_data.csv')
        }
        for key,(cont,blob_name,dst_path) in containers.items():
            dst = pathlib.Path(dst_path); dst.parent.mkdir(parents=True, exist_ok=True)
            blob = svc.get_container_client(cont).get_blob_client(blob_name)
            with open(dst,'wb') as f: f.write(blob.download_blob().readall())
        PY

    - name: Unit tests
      run: python -m unittest tests.text_tests.unit_tests

    - name: Integration tests
      run: python -m unittest tests.text_tests.integration_tests

    - name: Retrain model (creates shadow blob)
      id: retrain
      env:
        AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      run: |
        python -m retraining.text_retrain
    
    - name: Commit archived user data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name  "GitHub Action"
        git add datasets/text_data/archives/.
        git commit -m "Archive user text data [CI skip]" || echo "Nothing to commit"
        git push

    - name: Switch live service to shadow
      if: steps.retrain.outcome == 'success'
      run: |
        curl -sSL -X POST "$GATEWAY/admin/text/role" \
          -H "Content-Type: application/json" \
          -H "x-token: ${{ secrets.ADMIN_TOKEN }}" \
          --data '{"role":"shadow"}'
      env:
        GATEWAY: ${{ secrets.GATEWAY_URL }} 